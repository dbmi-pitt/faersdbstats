<?xml version="1.0" encoding="UTF-8"?>
<job>
  <name>stage_5_sqls</name>
  <description/>
  <extended_description/>
  <job_version/>
  <job_status>0</job_status>
  <directory>/</directory>
  <created_user>-</created_user>
  <created_date>2022/02/14 11:07:21.196</created_date>
  <modified_user>-</modified_user>
  <modified_date>2022/02/14 11:07:21.196</modified_date>
  <parameters>
    </parameters>
  <connection>
    <name>${DATABASE_NAME}</name>
    <server>${DATABASE_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${DATABASE_NAME}</database>
    <port>${DATABASE_PORT}</port>
    <username>${DATABASE_USERNAME}</username>
    <password>${DATABASE_PASSWORD}</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${DATABASE_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <slaveservers>
    </slaveservers>
  <job-log-table>
    <connection>${DATABASE_LOG_NAME}</connection>
    <schema>${DATABASE_LOG_SCHEMA}</schema>
    <table>${DATABASE_LOG_NAME}</table>
    <size_limit_lines>5000</size_limit_lines>
    <interval>1s</interval>
    <timeout_days>3.0</timeout_days>
    <field>
      <id>ID_JOB</id>
      <enabled>Y</enabled>
      <name>ID_JOB</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>JOBNAME</name>
    </field>
    <field>
      <id>STATUS</id>
      <enabled>Y</enabled>
      <name>STATUS</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>STARTDATE</id>
      <enabled>Y</enabled>
      <name>STARTDATE</name>
    </field>
    <field>
      <id>ENDDATE</id>
      <enabled>Y</enabled>
      <name>ENDDATE</name>
    </field>
    <field>
      <id>LOGDATE</id>
      <enabled>Y</enabled>
      <name>LOGDATE</name>
    </field>
    <field>
      <id>DEPDATE</id>
      <enabled>Y</enabled>
      <name>DEPDATE</name>
    </field>
    <field>
      <id>REPLAYDATE</id>
      <enabled>Y</enabled>
      <name>REPLAYDATE</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>Y</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>EXECUTING_SERVER</id>
      <enabled>Y</enabled>
      <name>EXECUTING_SERVER</name>
    </field>
    <field>
      <id>EXECUTING_USER</id>
      <enabled>Y</enabled>
      <name>EXECUTING_USER</name>
    </field>
    <field>
      <id>START_JOB_ENTRY</id>
      <enabled>Y</enabled>
      <name>START_JOB_ENTRY</name>
    </field>
    <field>
      <id>CLIENT</id>
      <enabled>Y</enabled>
      <name>CLIENT</name>
    </field>
  </job-log-table>
  <jobentry-log-table>
    <connection>${DATABASE_NAME}</connection>
    <schema>${DATABASE_LOG_SCHEMA}</schema>
    <table>${DATABASE_LOG_NAME}</table>
    <timeout_days>3.0</timeout_days>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>TRANSNAME</name>
    </field>
    <field>
      <id>JOBENTRYNAME</id>
      <enabled>Y</enabled>
      <name>STEPNAME</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>RESULT</id>
      <enabled>Y</enabled>
      <name>RESULT</name>
    </field>
    <field>
      <id>NR_RESULT_ROWS</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_ROWS</name>
    </field>
    <field>
      <id>NR_RESULT_FILES</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_FILES</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>Y</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>COPY_NR</id>
      <enabled>Y</enabled>
      <name>COPY_NR</name>
    </field>
  </jobentry-log-table>
  <channel-log-table>
    <connection>${DATABASE_NAME}</connection>
    <schema>${DATABASE_LOG_SCHEMA}</schema>
    <table>${DATABASE_LOG_NAME}</table>
    <timeout_days>3.0</timeout_days>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>LOGGING_OBJECT_TYPE</id>
      <enabled>Y</enabled>
      <name>LOGGING_OBJECT_TYPE</name>
    </field>
    <field>
      <id>OBJECT_NAME</id>
      <enabled>Y</enabled>
      <name>OBJECT_NAME</name>
    </field>
    <field>
      <id>OBJECT_COPY</id>
      <enabled>Y</enabled>
      <name>OBJECT_COPY</name>
    </field>
    <field>
      <id>REPOSITORY_DIRECTORY</id>
      <enabled>Y</enabled>
      <name>REPOSITORY_DIRECTORY</name>
    </field>
    <field>
      <id>FILENAME</id>
      <enabled>Y</enabled>
      <name>FILENAME</name>
    </field>
    <field>
      <id>OBJECT_ID</id>
      <enabled>Y</enabled>
      <name>OBJECT_ID</name>
    </field>
    <field>
      <id>OBJECT_REVISION</id>
      <enabled>Y</enabled>
      <name>OBJECT_REVISION</name>
    </field>
    <field>
      <id>PARENT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>PARENT_CHANNEL_ID</name>
    </field>
    <field>
      <id>ROOT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>ROOT_CHANNEL_ID</name>
    </field>
  </channel-log-table>
  <pass_batchid>N</pass_batchid>
  <shared_objects_file/>
  <entries>
    <entry>
      <name>Set AWS Credentials</name>
      <description/>
      <type>SHELL</type>
      <attributes/>
      <filename/>
      <work_directory/>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>#!/bin/bash
export "AWS_ACCESS_KEY_ID=${AWS_S3_ACCESS_KEY}"
#echo "AWS_S3_ACCESS_KEY = ${AWS_S3_ACCESS_KEY}"

export "AWS_SECRET_ACCESS_KEY=${AWS_S3_SECRET_KEY}"
#echo "AWS_S3_BUCKET_NAME=${AWS_S3_BUCKET_NAME}"

export "AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}"

aws configure list</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>112</xloc>
      <yloc>768</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_drilldown.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>------------------------------
--
-- Create standard_drug_outcome_drilldown table for use in joins to get all cases for a drug/outcome pair count
--
-- LTS COMPUTING LLC
------------------------------

set search_path = ${DATABASE_SCHEMA};

-- create indexes to speed up this SQL

--drop index if exists standard_case_drug_ix_1;
create index if not exists standard_case_drug_ix_1 on standard_case_drug(primaryid);
--drop index if exists standard_case_drug_ix_2;
create index if not exists standard_case_drug_ix_2 on standard_case_drug(isr);
--drop index if exists standard_case_drug_ix_3;
create index if not exists standard_case_drug_ix_3 on standard_case_drug(standard_concept_id);

--drop index if exists standard_case_adr_ix_1;
create index if not exists standard_case_adr_ix_1 on standard_case_adr(primaryid);
--drop index if exists standard_case_adr_ix_2;
create index if not exists standard_case_adr_ix_2 on standard_case_adr(isr);
--drop index if exists standard_case_adr_ix_3;
create index if not exists standard_case_adr_ix_3 on standard_case_adr(outcome_concept_id);

--drop index if exists standard_drug_outcome_count_ix_1;
create index if not exists standard_drug_outcome_count_ix_1 on standard_drug_outcome_count(drug_concept_id);
--drop index if exists standard_drug_outcome_count_ix_2;
create index if not exists standard_drug_outcome_count_ix_2 on standard_drug_outcome_count(outcome_concept_id);

--drop table if exists standard_drug_outcome_drilldown;
create table if not exists standard_drug_outcome_drilldown as
	select 
		a.drug_concept_id, 
		a.outcome_concept_id, 
		a.snomed_outcome_concept_id, 
		b.primaryid, null as isr, null as caseid
	from standard_drug_outcome_count a
		inner join standard_case_drug b
			on a.drug_concept_id = b.standard_concept_id
		inner join standard_case_adr c
			on a.outcome_concept_id = c.outcome_concept_id
			and b.primaryid = c.primaryid
	union
	select
		a.drug_concept_id,  
		a.outcome_concept_id, 
		a.snomed_outcome_concept_id,  
		null as primary_id, b.isr, null as caseid
	from standard_drug_outcome_count a
		inner join standard_case_drug b
			on a.drug_concept_id = b.standard_concept_id
		inner join standard_case_adr c
			on a.outcome_concept_id = c.outcome_concept_id
			and b.isr = c.isr;

-- populate the caseids that have a primaryid
update standard_drug_outcome_drilldown a
	set caseid = b.caseid
	from unique_all_case b
	where a.primaryid = b.primaryid;

-- populate the caseids that have an isr
update standard_drug_outcome_drilldown a
	set caseid = b.caseid
		from unique_all_case b
	where a.isr = b.isr
		and a.caseid is null;
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>656</xloc>
      <yloc>1904</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>map_meddra_to_snomed.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>------------------------------
-- map drug indications and adverse event outcomes (FAERS reactions) and associated drug/outcome pair counts from MedDRA preferred terms to SNOMED-CT concepts
--
-- LTS COMPUTING LLC
------------------------------

set search_path = ${DATABASE_SCHEMA};

-- populate standard_case_indication SNOMED-CT concepts
update standard_case_indication a
		set snomed_indication_concept_id = snomed_concept_id
	from meddra_snomed_mapping b
		where a.indication_concept_id = b.meddra_concept_id;

-- populate standard_case_adr SNOMED-CT concepts
update standard_case_adr a
	set snomed_outcome_concept_id = snomed_concept_id
from meddra_snomed_mapping b
	where a.outcome_concept_id = b.meddra_concept_id;

-- populate standard_drug_outcome_count SNOMED-CT concepts
update standard_drug_outcome_count a
	set snomed_outcome_concept_id = snomed_concept_id
		from meddra_snomed_mapping b
	where a.outcome_concept_id = b.meddra_concept_id;

-- populate standard_drug_outcome_statistics SNOMED-CT concepts
update standard_drug_outcome_statistics a
	set snomed_outcome_concept_id = snomed_concept_id
from meddra_snomed_mapping b
	where a.outcome_concept_id = b.meddra_concept_id;</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>352</xloc>
      <yloc>1904</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_contingency_table_part_1.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>/home/pentaho-secondary/projects-brb265/faers/faersdbstats/stage_5_sqls/derive_standard_drug_outcome_contingency_table_part_1.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>1600</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_count.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>------------------------------
--
-- This SQL script creates drug/outcome combination case counts (counts for pairs of drug RxNorm concept_id, outcome (reaction) Meddra concept_id) 
-- and stores the combination case counts in a new table called standard_drug_outcome_count
--
-- LTS COMPUTING LLC
------------------------------

set search_path = ${DATABASE_SCHEMA};

drop table if exists standard_drug_outcome_count;
create table standard_drug_outcome_count as
select drug_concept_id, outcome_concept_id, count(*) as drug_outcome_pair_count, cast(null as integer) as snomed_outcome_concept_id
from (
	select 'PRIMARYID' || a.primaryid as case_key, a.standard_concept_id as drug_concept_id, b.outcome_concept_id, cast(null as integer) as snomed_outcome_concept_id
	from standard_case_drug a
	inner join standard_case_adr b
	on a.primaryid = b.primaryid and a.isr is null and b.isr is null
	union 
	select 'ISR' || a.isr as case_key, a.standard_concept_id as drug_concept_id, b.outcome_concept_id, cast(null as integer) as snomed_outcome_concept_id
	from standard_case_drug a
	inner join standard_case_adr b
	on a.isr = b.isr and a.isr is not null and b.isr is not null
) aa
group by drug_concept_id, outcome_concept_id;
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>144</xloc>
      <yloc>1296</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_case_adr.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>------------------------------
--
-- This SQL script converts the unique legacy LAERS and current FAERS case reactions (adverse event outcomes) MedDRA preferred terms 
-- into MedDRA concept ids in a new table called standard_case_adr 
--
-- LTS COMPUTING LLC
------------------------------

set search_path = ${DATABASE_SCHEMA};

-- create indexes on reac table for improved performance in this SQL
--drop index if exists ix_reac_1;
--drop index if exists ix_reac_2;
create index if not exists ix_reac_1 on reac (upper(pt));
create index if not exists ix_reac_2 on reac (primaryid);
analyze verbose reac;

-- create indexes on reac_legacy table for improved performance in this SQL
--drop index if exists ix_reac_legacy_1;
--drop index if exists ix_reac_legacy_2;
create index if not exists ix_reac_legacy_1 on reac_legacy (upper(pt));
create index if not exists ix_reac_legacy_2 on reac_legacy (isr);
analyze verbose reac_legacy;

--drop table if exists standard_case_adr;
create table if not exists standard_case_adr as
select distinct a.primaryid, a.isr, b.pt, c.concept_id as outcome_concept_id, cast(null as integer) as snomed_outcome_concept_id
	from unique_all_case a
	inner join reac b
		on a.primaryid = b.primaryid
	inner join staging_vocabulary.concept c
		on upper(b.pt) = upper(c.concept_name)
		and c.vocabulary_id = 'MedDRA'
		where a.isr is null
union
select distinct a.primaryid, a.isr, b.pt, c.concept_id as outcome_concept_id, cast(null as integer) as snomed_outcome_concept_id
	from unique_all_case a
inner join reac_legacy b
		on a.isr = b.isr
	inner join staging_vocabulary.concept c
		on upper(b.pt) = upper(c.concept_name)
		and c.vocabulary_id = 'MedDRA'
		where a.isr is not null;
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>384</xloc>
      <yloc>1184</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_case_indication.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>------------------------------
--
-- This SQL script converts the indication MedDRA preferred terms into MedDRA concept ids for all unique legacy and current cases
-- in a new table called standard_case_indication 
-- Note. We use a regex to remove leading white space in the indication preferred term field
--
-- LTS COMPUTING LLC
------------------------------

set search_path = ${DATABASE_SCHEMA};

--drop table if exists standard_case_indication; 
create table if not exists standard_case_indication as
select distinct a.primaryid, a.isr, indi_drug_seq, b.indi_pt, c.concept_id as indication_concept_id, cast(null as integer) as snomed_indication_concept_id
	from unique_all_case a
	inner join indi b
		on a.primaryid = b.primaryid
	inner join staging_vocabulary.concept c
		on upper(regexp_replace(b.indi_pt,'^ +','','gi')) = upper(c.concept_name) 
		and c.vocabulary_id = 'MedDRA'
		where a.isr is null
union
select distinct a.primaryid, a.isr, drug_seq, b.indi_pt, c.concept_id as indication_concept_id, cast(null as integer) as snomed_indication_concept_id
	from unique_all_case a
	inner join indi_legacy b
		on a.isr = b.isr
	inner join staging_vocabulary.concept c
		on upper(regexp_replace(b.indi_pt,'^ +','','gi')) = upper(c.concept_name) 
		and c.vocabulary_id = 'MedDRA'
		where a.isr is not null;
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>112</xloc>
      <yloc>1184</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_case_outcome_category.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>------------------------------
--
-- This SQL script derives the SNOMED-CT concept codes for the legacy LARES and current FAERS outcome (categories) in a new table called standard_case_outcome_category
-- limited to just the unique cases.
--
-- Map the outcome categories to the following SNOMED codes:
--
-- CA "Congenital Anomaly" = SNOMED concept code: 107656002, SNOMED concept: "Congenital anomaly", OHDSI concept_id = 4029540
-- DE "Death" = SNOMED concept code: 419620001, SNOMED concept: "Death" , OHDSI concept_id = 4306655
-- DS "Disability" = SNOMED concept code: 21134002, SNOMED concept: "Disability", OHDSI concept_id = 4052648
-- HO "Hospitalization - Initial or Prolonged" = SNOMED concept code: 32485007, SNOMED concept: "Hospital admission", OHDSI concept_id = 8715
-- LT "Life-Threatening" = SNOMED concept code: 442452003, SNOMED concept: "Life threatening severity" OHDSI, concept_id = 40483553
-- OT "Other" = SNOMED concept code: 10003008, SNOMED concept: "Non-specific", OHDSI concept_id = 4001594
-- RI "Required Intervention to Prevent Permanent Impairment/Damage" = SNOMED concept code: 3890004, SNOMED concept: "Treatment required for", OHDSI concept_id = 4191370
--
-- NOTE. Around 25% of the cases in the FAERS demo table and 6% of LAERS do not have an outcome in the outc table
-- so in this sql we use a left outer join and some of the outc_codes will be null.
--
-- LTS COMPUTING LLC
------------------------------

set search_path = ${DATABASE_SCHEMA};

--drop table if exists standard_case_outcome_category;
create table if not exists standard_case_outcome_category as
(
	with cte1 as (
	select distinct a.primaryid, a.isr, b.outc_code
	from unique_all_case a
	left outer join outc b
	on a.primaryid = b.primaryid
	where a.isr is null
	union
	select distinct a.primaryid, a.isr, b.outc_cod
	from unique_all_case a
	left outer join outc_legacy b
	on a.isr = b.isr
	where a.isr is not null
	
	),
	cte2 as (
	select distinct primaryid, isr, outc_code, 
	case 
		when (outc_code = 'CA') then 4029540 	-- SNOMED concept: "Congenital anomaly", OHDSI concept_id = 4029540
		when (outc_code = 'DE') then 4306655 	-- SNOMED concept: "Death" , OHDSI concept_id = 4306655
		when (outc_code = 'DS') then 4052648  	-- SNOMED concept: "Disability", OHDSI concept_id = 4052648
		when (outc_code = 'HO') then 8715		-- SNOMED concept: "Hospital admission", OHDSI concept_id = 8715
		when (outc_code = 'LT') then 40483553	-- SNOMED concept: "Life threatening severity" OHDSI, concept_id = 40483553
		when (outc_code = 'OT') then 4001594	-- SNOMED concept: "Non-specific", OHDSI concept_id = 4001594
		when (outc_code = 'RI') then 4191370	-- SNOMED concept: "Treatment required for", OHDSI concept_id = 4191370
	end as snomed_concept_id
	from cte1
	)
select * from cte2
);
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>864</xloc>
      <yloc>1040</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>standardize_combined_drug_mapping.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>--NOTE THIS STEP THROWS ERRORS IF NOT "SQL from file"</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>${Internal.Entry.Current.Directory}/standardize_combined_drug_mapping.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>544</xloc>
      <yloc>1040</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>create_usagi_import_table.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>-- Create staging table to import USAGI manually mapped drug names
--
-- LTS Computing LLC
-----------------------------------------------------------------------------------------------
set search_path = ${DATABASE_SCHEMA};

--drop table if exists usagi_import;
CREATE TABLE IF NOT EXISTS usagi_import
(
  source_code character varying,
  source_concept_id character varying,
  source_vocabulary_id character varying,
  source_code_description character varying,
  target_concept_id character varying,
  target_vocabulary_id character varying,
  valid_start_date character varying,
  valid_end_date character varying,
  invalid_reason character varying
);</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>656</xloc>
      <yloc>880</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>map_all_drugname_to_rxnorm</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>${Internal.Entry.Current.Directory}/map_all_drugname_to_rxnorm.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>112</xloc>
      <yloc>1040</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_unique_all_case.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>-- Transform the LAERS legacy demo data into the same format as the FAERS current data so we can combine demographic data across both databases and run logic to remove duplicate cases across them both
-- There is no real LAERS case version so we default to '0' to ensure that LAERS data will sort before FAERS data case version (FAERS case version is always populated and never less than '1')
-- There is no real LAERS primaryid but we generate it from CASE and case version
-- We translate LAERS country names to FAERS 2 char country codes with a join to the country_code table
--
-- We perform single imputation of missing 'key' demographic fields for multiple reports within the same case producing a new table demo_with_imputed_keys.
--
-- We followed the single imputation process in the book "Data Mining Applications in Engineering and Medicine" 
--		by Elisabetta Poluzzi1, Emanuel Raschi1, Carlo Piccinni1 and Fabrizio De Ponti1
--		ISBN 978-953-51-0720-0: 
--		See Chapter 12: Data Mining Techniques in Pharmacovigilance: Analysis of the Publicly Accessible FDA Adverse Event Reporting System (AERS)  
-- 		we use the same demographic key fields:  age, event_dt, sex, reporter_country.
-- 
-- The 'key' demographic fields are required in later processing to remove duplicate cases.
-- 
-- We will only impute single missing case demo key values for a case where there is at least one case record with a fully populated set of demo keys 
-- and we populate (impute) the value of a missing demo key field using the max value of the demo key field for the same case.
--
-- LTS Computing LLC
-------------------------------

set search_path = ${DATABASE_SCHEMA};

-- generate a table to lookup concatenated string of current drugnames by primaryid
drop table if exists drugname_list;
create table drugname_list as
select primaryid, upper(string_agg(drugname, '|' order by drugname)) as drugname_list
from drug
group by primaryid;

-- generate a table to lookup concatenated string of reaction preferred terms by primaryid
drop table if exists reac_pt_list;
create table reac_pt_list as
select primaryid, upper(string_agg(pt, '|' order by pt)) as reac_pt_list
from reac
group by primaryid;

-- generate a table of current data demographics by caseid
drop table if exists casedemo;
create table casedemo as
select caseid, caseversion, i_f_code, event_dt, age, sex, reporter_country, d.primaryid, drugname_list, reac_pt_list, fda_dt
from demo d
left outer join drugname_list dl
on d.primaryid = dl.primaryid 
left outer join reac_pt_list rpl
on d.primaryid = rpl.primaryid;

----------------------

-- generate a table to lookup concatenated string of legacy drugnames by isr
drop table if exists drugname_legacy_list;
create table drugname_legacy_list as
select isr, upper(string_agg(drugname, '|' order by drugname)) as drugname_list 
from drug_legacy
group by isr;

-- generate a table to lookup concatenated string of legacy reaction preferred terms by isr
drop table if exists reac_pt_legacy_list;
create table reac_pt_legacy_list as
select isr, upper(string_agg(pt, '|' order by pt)) as reac_pt_list
from reac_legacy
group by isr;

-- generate a table of legacy case demographics by case id
drop table if exists casedemo_legacy;
create table casedemo_legacy as
select "CASE", i_f_cod, event_dt, age, gndr_cod, reporter_country, d.isr, drugname_list, reac_pt_list, fda_dt
from demo_legacy d
left outer join drugname_legacy_list dl
on d.isr = dl.isr 
left outer join reac_pt_legacy_list rpl
on d.isr = rpl.isr;

------------------------------

-- create a combined set of all case demographics with drug list and reaction (outcome) lists across all the LAERS legacy data and FAERS current data
drop table if exists all_casedemo;
create table all_casedemo as 
select 'FAERS' as database, caseid, cast(null as varchar) as isr, caseversion, i_f_code, event_dt, age, sex, reporter_country, primaryid, 
drugname_list, reac_pt_list, fda_dt, null as imputed_field_name 
from casedemo 
union
select 'LAERS' as database, "CASE" as caseid, isr, cast ('0' as varchar) as caseversion, i_f_cod as i_f_code, event_dt, age, gndr_cod as sex, e.country_code as reporter_country, cast("CASE" || '0' as varchar) as primaryid, 
drugname_list, reac_pt_list, fda_dt, null as imputed_field_name 
from casedemo_legacy a 
left outer join country_code e
on upper(a.reporter_country) = upper(e.country_name);

------------------------------

-- perform single imputation of missing 'key' demographic fields for multiple reports within the same case across all the legacy and current data

-- create table of default demo event_dt key value for each case where all the key fields are populated on at least one report for that case
drop table if exists default_all_casedemo_event_dt_keys; 
create table default_all_casedemo_event_dt_keys as 
select caseid, age, sex, reporter_country, max(event_dt) as default_event_dt
from all_casedemo 
where caseid is not null and event_dt is not null and age is not null and sex is not null and reporter_country is not null
group by caseid, age, sex, reporter_country;

-- single imputation of missing event_dt 
update all_casedemo a
set event_dt = default_event_dt, imputed_field_name = 'event_dt' 
from default_all_casedemo_event_dt_keys d
where a.caseid = d.caseid and a.age = d.age and a.sex = d.sex and a.reporter_country = d.reporter_country
and a.caseid is not null and a.event_dt is null and a.age is not null and a.sex is not null and a.reporter_country is not null;

-- create table of default demo age key value for each case where all the key fields are populated on at least one report for that case
drop table if exists default_all_casedemo_age_keys; 
create table default_all_casedemo_age_keys as 
select caseid, event_dt, sex, reporter_country, max(age) as default_age
from all_casedemo 
where caseid is not null and event_dt is not null and age is not null and sex is not null and reporter_country is not null
group by caseid, event_dt, sex, reporter_country;

-- single imputation of missing age 
update all_casedemo a 
set age = default_age, imputed_field_name = 'age'  
from default_all_casedemo_age_keys d
where a.caseid = d.caseid and a.event_dt = d.event_dt and a.sex = d.sex and a.reporter_country = d.reporter_country
and a.caseid is not null and a.event_dt is not null and a.age is null and a.sex is not null and a.reporter_country is not null;

-- create table of default demo gender key value for each case where all the key fields are populated on at least one report for that case
drop table if exists default_all_casedemo_sex_keys; 
create table default_all_casedemo_sex_keys as 
select caseid, event_dt, age, reporter_country, max(sex) as default_sex
from all_casedemo 
where caseid is not null and event_dt is not null and age is not null and sex is not null and reporter_country is not null
group by caseid, event_dt, age, reporter_country;

-- single imputation of missing gender
update all_casedemo a 
set sex = default_sex, imputed_field_name = 'sex' 
from default_all_casedemo_sex_keys d
where a.caseid = d.caseid and a.event_dt = d.event_dt and a.age = d.age and a.reporter_country = d.reporter_country
and a.caseid is not null and a.event_dt is not null and a.age is not null and a.sex is null and a.reporter_country is not null;

-- create table of default demo reporter_country key value for each case where all the key fields are populated on at least one report for that case
drop table if exists default_all_casedemo_reporter_country_keys; 
create table default_all_casedemo_reporter_country_keys as 
select caseid, event_dt, age, sex, max(reporter_country) as default_reporter_country
from all_casedemo 
where caseid is not null and event_dt is not null and age is not null and sex is not null and reporter_country is not null
group by caseid, event_dt, age, sex;

-- single imputation of missing reporter_country
update all_casedemo a
set reporter_country = default_reporter_country, imputed_field_name = 'reporter_country'  
from default_all_casedemo_reporter_country_keys d
where a.caseid = d.caseid and a.event_dt = d.event_dt and a.age = d.age and a.sex = d.sex
and a.caseid is not null and a.event_dt is not null and a.age is not null and a.sex is not null and a.reporter_country is null;

------------------------------

-- get the latest case row for each case across both the legacy LAERS and current FAERS data based on CASE ID
drop table if exists unique_all_casedemo;
create table unique_all_casedemo as
  select database, caseid, isr, caseversion, i_f_code, event_dt, age, sex, reporter_country, primaryid, drugname_list, reac_pt_list, fda_dt
   from (
     select *, 
       row_number() over(partition by caseid order by primaryid desc, database desc, fda_dt desc, i_f_code, isr desc) as row_num 
     from all_casedemo 
   ) a where a.row_num = 1;

-- remove any duplicates based on fully populated matching demographic key fields and exact match on list of drugs and list of outcomes (FAERS reactions)
-- NOTE. when using this table for subsequent joins in the ETL process, join to FAERS data using primaryid and join to LAERS data using isr
drop table if exists unique_all_case;   
create table unique_all_case as
select caseid, case when isr is not null then null else primaryid end as primaryid, isr 
from (
	select caseid, primaryid, isr, 
	row_number() over(partition by event_dt, age, sex, reporter_country, drugname_list, reac_pt_list order by primaryid desc, database desc, fda_dt desc, i_f_code, isr desc) as row_num 
	from unique_all_casedemo 
	where caseid is not null and event_dt is not null and age is not null and sex is not null and reporter_country is not null and drugname_list is not null and reac_pt_list is not null
) a where a.row_num = 1
union 
  select caseid, case when isr is not null then null else primaryid end as primaryid, isr 
    from unique_all_casedemo 
      where caseid is null or event_dt is null or age is null or sex is null or reporter_country is null or drugname_list is null or reac_pt_list is null;
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>112</xloc>
      <yloc>880</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Wait for 3s</name>
      <description/>
      <type>DELAY</type>
      <attributes/>
      <maximumTimeout>3</maximumTimeout>
      <scaletime>0</scaletime>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>656</xloc>
      <yloc>768</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Set job variables</name>
      <description/>
      <type>SET_VARIABLES</type>
      <attributes/>
      <replacevars>Y</replacevars>
      <filename>${BASE_FILE_DIR}/faers_config.config</filename>
      <file_variable_type>JVM</file_variable_type>
      <fields>
        <field>
          <variable_name>FILE_DIR</variable_name>
          <variable_value>${BASE_FILE_DIR}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>FAERSDBSTATS_REPO_LOCATION</variable_name>
          <variable_value>${FAERSDBSTATS_REPO_LOCATION}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>CEM_DOWNLOAD_DATA_FOLDER</variable_name>
          <variable_value>${CEM_DOWNLOAD_DATA_FOLDER}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>AWS_S3_BUCKET_NAME</variable_name>
          <variable_value>${AWS_S3_BUCKET_NAME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>AWS_S3_ACCESS_KEY</variable_name>
          <variable_value>${AWS_S3_ACCESS_KEY}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>AWS_S3_SECRET_KEY</variable_name>
          <variable_value>${AWS_S3_SECRET_KEY}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_HOST</variable_name>
          <variable_value>${DATABASE_HOST}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_NAME</variable_name>
          <variable_value>${DATABASE_NAME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_SCHEMA</variable_name>
          <variable_value>${DATABASE_SCHEMA}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_USERNAME</variable_name>
          <variable_value>${DATABASE_USERNAME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_PASSWORD</variable_name>
          <variable_value>${DATABASE_PASSWORD}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_LOG_SCHEMA</variable_name>
          <variable_value>${DATABASE_LOG_SCHEMA}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>LOAD_NEW_QUARTER</variable_name>
          <variable_value>${LOAD_NEW_QUARTER}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>LOAD_NEW_YEAR</variable_name>
          <variable_value>${LOAD_NEW_YEAR}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>LOAD_ALL_TIME</variable_name>
          <variable_value>${LOAD_ALL_TIME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>CEM_ORANGE_BOOK_DOWNLOAD_FILENAME</variable_name>
          <variable_value>${CEM_ORANGE_BOOK_DOWNLOAD_FILENAME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>BASE_FILE_DIR</variable_name>
          <variable_value>${BASE_FILE_DIR}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
      </fields>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>352</xloc>
      <yloc>656</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Start</name>
      <description/>
      <type>SPECIAL</type>
      <attributes/>
      <start>Y</start>
      <dummy>N</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>112</xloc>
      <yloc>656</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_statistics.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>------------------------------
--
-- This SQL script creates a statistics table called standard_drug_outcome_stats (using the counts from the previously calculated 2x2 contingency table)
-- with the following statistics for each drug/outcome pair:
--
-- 1) Case count
-- 2) Proportional Reporting Ratio (PRR) along with the 95% CI upper and lower values
-- 3) Reporting Odds Ratio (ROR) along with the 95% CI upper and lower values
--
-- PRR for pair:(drug P, outcome R) is calculated as (A / (A + B)) / (C / (C + D)
--
-- ROR for pair:(drug P, outcome R) is calculated as (A / C) / (B / D)
--
-- Where:
--		A = case_count for the pair:(drug P, outcome R)
--		B = sum(case_count) for all pairs:(drug P, all outcomes except outcome R)
--		C = sum(case_count) for all pairs:(all drugs except drug P, outcome R)
--		D = sum(case_count) for all pairs:(all drugs except drug P, all outcomes except outcome R)
--
-- Note if C is 0 then the resulting PRR and ROR values will be null. Potentially a relatively high constant value
-- could be assigned instead, to indicate a potential PRR and ROR signal in these cases.
--
--
-- Standard deviations are obtained from Douglas G Altman's Practical Statistics for Medical Research. 1999. Chapter 10.11. Page 267 
--
-- LTS COMPUTING LLC
------------------------------

set search_path = ${DATABASE_SCHEMA};

--drop table if exists standard_drug_outcome_statistics;
create table if not exists standard_drug_outcome_statistics as
select drug_concept_id, outcome_concept_id, cast(null as integer) as snomed_outcome_concept_id, 
    count_a as case_count,
    round((count_a / (count_a + count_b)) / (count_c / (count_c + count_d)),5) as prr,
    round(exp(ln((count_a / (count_a + count_b)) / (count_c / (count_c + count_d)))+1.96*sqrt((1.0/count_a)-(1.0/(count_a+count_b))+(1.0/count_c)-(1.0/(count_c+count_d)))),5) as prr_95_percent_upper_confidence_limit,
    round(exp(ln((count_a / (count_a + count_b)) / (count_c / (count_c + count_d)))-1.96*sqrt((1.0/count_a)-(1.0/(count_a+count_b))+(1.0/count_c)-(1.0/(count_c+count_d)))),5) as prr_95_percent_lower_confidence_limit,
    round(((count_a / count_c) / (count_b / count_d)),5) as ror,
    round(exp((ln((count_a / count_c) / (count_b / count_d)))+1.96*sqrt((1.0/count_a)+(1.0/count_b)+(1.0/count_c)+(1.0/count_d))),5) as ror_95_percent_upper_confidence_limit,
    round(exp((ln((count_a / count_c) / (count_b / count_d)))-1.96*sqrt((1.0/count_a)+(1.0/count_b)+(1.0/count_c)+(1.0/count_d))),5) as ror_95_percent_lower_confidence_limit
from standard_drug_outcome_contingency_table;
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>160</xloc>
      <yloc>1888</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Log STAGE 5 COMPLETE</name>
      <description/>
      <type>SHELL</type>
      <attributes/>
      <filename/>
      <work_directory/>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>#!/bin/bash
log_location=${BASE_FILE_DIR}/logs/${LOG_FILENAME}
printf '\n' >> $log_location
echo "#######################################################" >> $log_location
echo "################ STAGE 5 COMPLETE #####################" >> $log_location
echo "#######################################################" >> $log_location
printf '\n\n' >> $log_location
echo ' You might have a database administrator vacuum db and reindex ' >> $log_location</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>96</xloc>
      <yloc>2000</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_contingency_table_part_5.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>F</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>/home/pentaho-secondary/projects-brb265/faers/faersdbstats/stage_5_sqls/derive_standard_drug_outcome_contingency_table_part_5.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>1792</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_contingency_table_part_2.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>/home/pentaho-secondary/projects-brb265/faers/faersdbstats/stage_5_sqls/derive_standard_drug_outcome_contingency_table_part_2.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>1648</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_contingency_table_part_3.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>/home/pentaho-secondary/projects-brb265/faers/faersdbstats/stage_5_sqls/derive_standard_drug_outcome_contingency_table_part_3.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>1696</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_contingency_table_part_4.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>/home/pentaho-secondary/projects-brb265/faers/faersdbstats/stage_5_sqls/derive_standard_drug_outcome_contingency_table_part_4.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>1744</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Wait for 3s (2)</name>
      <description/>
      <type>DELAY</type>
      <attributes/>
      <maximumTimeout>3</maximumTimeout>
      <scaletime>0</scaletime>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>880</xloc>
      <yloc>1184</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Wait for 3s (3)</name>
      <description/>
      <type>DELAY</type>
      <attributes/>
      <maximumTimeout>3</maximumTimeout>
      <scaletime>0</scaletime>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>1296</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Wait for 3s (4)</name>
      <description/>
      <type>DELAY</type>
      <attributes/>
      <maximumTimeout>3</maximumTimeout>
      <scaletime>0</scaletime>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>672</xloc>
      <yloc>1552</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>create standard_drug_outcome_contingency_table from cem_ddl.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>-- faers.standard_drug_outcome_contingency_table definition

-- Drop table

-- DROP TABLE faers.standard_drug_outcome_contingency_table;

set search_path = ${DATABASE_SCHEMA};

CREATE TABLE if not exists faers.standard_drug_outcome_contingency_table (
	drug_concept_id int4 NULL,
	outcome_concept_id int4 NULL,
	count_a int8 NULL,
	count_b numeric NULL,
	count_c numeric NULL,
	count_d numeric NULL
);
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>880</xloc>
      <yloc>1296</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_contingency_table.sql (all)</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>/home/pentaho-secondary/projects-brb265/faers/faersdbstats/stage_5_sqls/derive_standard_drug_outcome_contingency_table.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>208</xloc>
      <yloc>1440</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Log "STAGE 5 TOOK DERIVE_* step SHORT ROUTE"</name>
      <description/>
      <type>SHELL</type>
      <attributes/>
      <filename/>
      <work_directory/>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>#!/bin/bash
log_location=${BASE_FILE_DIR}/logs/${LOG_FILENAME}
printf '\n' >> $log_location
echo "################ STAGE 5 TOOK DERIVE_* step SHORT ROUTE #####################" >> $log_location
printf '\n' >> $log_location</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>160</xloc>
      <yloc>1536</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Log "STAGE 5 TOOK DERIVE FAILED SO DERIVE_* step LONG ROUTE"</name>
      <description/>
      <type>SHELL</type>
      <attributes/>
      <filename/>
      <work_directory/>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>#!/bin/bash
log_location=${BASE_FILE_DIR}/logs/${LOG_FILENAME}
printf '\n' >> $log_location
echo "################ STAGE 5 TOOK DERIVE FAILED SO DERIVE_* step LONG ROUTE #####################" >> $log_location
printf '\n' >> $log_location</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>1520</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Log "STAGE 5 STARTED"</name>
      <description/>
      <type>SHELL</type>
      <attributes/>
      <filename/>
      <work_directory/>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>#!/bin/bash
log_location=${BASE_FILE_DIR}/logs/${LOG_FILENAME}
printf '\n' >> $log_location
echo "################ Stage_5_SQLs has started #####################" >> $log_location
printf '\n' >> $log_location</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>656</xloc>
      <yloc>656</yloc>
      <attributes_kjc/>
    </entry>
  </entries>
  <hops>
    <hop>
      <from>create_usagi_import_table.sql</from>
      <to>map_all_drugname_to_rxnorm</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>N</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_case_indication.sql</from>
      <to>derive_standard_case_adr.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_case_outcome_category.sql</from>
      <to>derive_standard_case_indication.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>standardize_combined_drug_mapping.sql</from>
      <to>derive_standard_case_outcome_category.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>map_meddra_to_snomed.sql</from>
      <to>derive_standard_drug_outcome_drilldown.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_unique_all_case.sql</from>
      <to>create_usagi_import_table.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>map_all_drugname_to_rxnorm</from>
      <to>standardize_combined_drug_mapping.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Start</from>
      <to>Set job variables</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Set AWS Credentials</from>
      <to>Wait for 3s</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_drilldown.sql</from>
      <to>Log STAGE 5 COMPLETE</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_statistics.sql</from>
      <to>map_meddra_to_snomed.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_contingency_table_part_5.sql</from>
      <to>derive_standard_drug_outcome_statistics.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_contingency_table_part_2.sql</from>
      <to>derive_standard_drug_outcome_contingency_table_part_3.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_contingency_table_part_3.sql</from>
      <to>derive_standard_drug_outcome_contingency_table_part_4.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_contingency_table_part_4.sql</from>
      <to>derive_standard_drug_outcome_contingency_table_part_5.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_case_adr.sql</from>
      <to>Wait for 3s (2)</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Wait for 3s (2)</from>
      <to>derive_standard_drug_outcome_count.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>N</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_count.sql</from>
      <to>Wait for 3s (3)</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_contingency_table_part_1.sql</from>
      <to>Wait for 3s (4)</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Wait for 3s (4)</from>
      <to>derive_standard_drug_outcome_contingency_table_part_2.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Wait for 3s (3)</from>
      <to>create standard_drug_outcome_contingency_table from cem_ddl.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>create standard_drug_outcome_contingency_table from cem_ddl.sql</from>
      <to>derive_standard_drug_outcome_contingency_table.sql (all)</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_contingency_table.sql (all)</from>
      <to>Log "STAGE 5 TOOK DERIVE_* step SHORT ROUTE"</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Log "STAGE 5 TOOK DERIVE_* step SHORT ROUTE"</from>
      <to>derive_standard_drug_outcome_statistics.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_contingency_table.sql (all)</from>
      <to>Log "STAGE 5 TOOK DERIVE FAILED SO DERIVE_* step LONG ROUTE"</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Log "STAGE 5 TOOK DERIVE FAILED SO DERIVE_* step LONG ROUTE"</from>
      <to>derive_standard_drug_outcome_contingency_table_part_1.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Set job variables</from>
      <to>Log "STAGE 5 STARTED"</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Log "STAGE 5 STARTED"</from>
      <to>Set AWS Credentials</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Wait for 3s</from>
      <to>derive_unique_all_case.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
  </hops>
  <notepads>
    <notepad>
      <note>Stage 5 - Drug Mapping

Prereq's
  having run...
    stage_1 then...
    stage_2 then...
    stage_3_domain_transform
  and
    stage_3_domain_transform (if data from 2012 Q3 or older)
    stage_4_meta

ABOUT THIS STAGE
-derive_unique_all_case.sql			-makes LAERS data like FAERS data and removes duplicates created in process
-map_all_drugname_to_rxnorm
-standardize_combined_drug_mapping
-derive_standard_case_outcome_category
-derive_standard_case_indication.sql
-derive_standard_case_adr.sql
-derive_standard_drug_outcome_count.sql
-derive_standard_drug_outcome_contingency_table.sql    -create index if not exists
-derive_standard_drug_outcome_statistics.sql
-map_meddra_to_snomed.sql
-derive_standard_drug_outcome_drilldown.sql       -create table if not exists   -create index if not exists

Troubleshooting:
if "Logging" tab stops producing output restart spoon
if Java Null Pointer Error (and/or job 'job") restart spoon then rebuild failing step as if new


</note>
      <xloc>0</xloc>
      <yloc>0</yloc>
      <width>773</width>
      <heigth>520</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>^creates standard_drug_outcome_count table</note>
      <xloc>32</xloc>
      <yloc>1360</yloc>
      <width>320</width>
      <heigth>27</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>^combined_drug_mapping</note>
      <xloc>117</xloc>
      <yloc>1107</yloc>
      <width>189</width>
      <heigth>27</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>wants to review</note>
      <xloc>304</xloc>
      <yloc>960</yloc>
      <width>115</width>
      <heigth>27</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>our natural product vocabulary goes here
</note>
      <xloc>160</xloc>
      <yloc>1024</yloc>
      <width>285</width>
      <heigth>44</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>bring in our new de-duplication method</note>
      <xloc>528</xloc>
      <yloc>1168</yloc>
      <width>272</width>
      <heigth>27</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>bring in xiaotong's ddi stats</note>
      <xloc>192</xloc>
      <yloc>1984</yloc>
      <width>195</width>
      <heigth>27</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <attributes>
    <group>
      <name>METASTORE.pentaho</name>
      <attribute>
        <key>Default Run Configuration</key>
        <value>{"namespace":"pentaho","id":"Default Run Configuration","name":"Default Run Configuration","description":"Defines a default run configuration","metaStoreName":null}</value>
      </attribute>
    </group>
    <group>
      <name>{"_":"Embedded MetaStore Elements","namespace":"pentaho","type":"Default Run Configuration"}</name>
    </group>
  </attributes>
</job>
