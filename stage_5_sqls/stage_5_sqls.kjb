<?xml version="1.0" encoding="UTF-8"?>
<job>
  <name>stage_5_sqls</name>
  <description/>
  <extended_description/>
  <job_version/>
  <job_status>0</job_status>
  <directory>/</directory>
  <created_user>-</created_user>
  <created_date>2022/02/14 11:07:21.196</created_date>
  <modified_user>-</modified_user>
  <modified_date>2022/02/14 11:07:21.196</modified_date>
  <parameters>
    </parameters>
  <connection>
    <name>${DATABASE_NAME}</name>
    <server>${DATABASE_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${DATABASE_NAME}</database>
    <port>${DATABASE_PORT}</port>
    <username>${DATABASE_USERNAME}</username>
    <password>${DATABASE_PASSWORD}</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${DATABASE_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <slaveservers>
    </slaveservers>
  <job-log-table>
    <connection>${DATABASE_LOG_NAME}</connection>
    <schema>${DATABASE_LOG_SCHEMA}</schema>
    <table>${DATABASE_LOG_NAME}</table>
    <size_limit_lines>5000</size_limit_lines>
    <interval>1s</interval>
    <timeout_days>3.0</timeout_days>
    <field>
      <id>ID_JOB</id>
      <enabled>Y</enabled>
      <name>ID_JOB</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>JOBNAME</name>
    </field>
    <field>
      <id>STATUS</id>
      <enabled>Y</enabled>
      <name>STATUS</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>STARTDATE</id>
      <enabled>Y</enabled>
      <name>STARTDATE</name>
    </field>
    <field>
      <id>ENDDATE</id>
      <enabled>Y</enabled>
      <name>ENDDATE</name>
    </field>
    <field>
      <id>LOGDATE</id>
      <enabled>Y</enabled>
      <name>LOGDATE</name>
    </field>
    <field>
      <id>DEPDATE</id>
      <enabled>Y</enabled>
      <name>DEPDATE</name>
    </field>
    <field>
      <id>REPLAYDATE</id>
      <enabled>Y</enabled>
      <name>REPLAYDATE</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>Y</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>EXECUTING_SERVER</id>
      <enabled>Y</enabled>
      <name>EXECUTING_SERVER</name>
    </field>
    <field>
      <id>EXECUTING_USER</id>
      <enabled>Y</enabled>
      <name>EXECUTING_USER</name>
    </field>
    <field>
      <id>START_JOB_ENTRY</id>
      <enabled>Y</enabled>
      <name>START_JOB_ENTRY</name>
    </field>
    <field>
      <id>CLIENT</id>
      <enabled>Y</enabled>
      <name>CLIENT</name>
    </field>
  </job-log-table>
  <jobentry-log-table>
    <connection>${DATABASE_NAME}</connection>
    <schema>${DATABASE_LOG_SCHEMA}</schema>
    <table>${DATABASE_LOG_NAME}</table>
    <timeout_days>3.0</timeout_days>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>TRANSNAME</name>
    </field>
    <field>
      <id>JOBENTRYNAME</id>
      <enabled>Y</enabled>
      <name>STEPNAME</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>RESULT</id>
      <enabled>Y</enabled>
      <name>RESULT</name>
    </field>
    <field>
      <id>NR_RESULT_ROWS</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_ROWS</name>
    </field>
    <field>
      <id>NR_RESULT_FILES</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_FILES</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>Y</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>COPY_NR</id>
      <enabled>Y</enabled>
      <name>COPY_NR</name>
    </field>
  </jobentry-log-table>
  <channel-log-table>
    <connection>${DATABASE_NAME}</connection>
    <schema>${DATABASE_LOG_SCHEMA}</schema>
    <table>${DATABASE_LOG_NAME}</table>
    <timeout_days>3.0</timeout_days>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>LOGGING_OBJECT_TYPE</id>
      <enabled>Y</enabled>
      <name>LOGGING_OBJECT_TYPE</name>
    </field>
    <field>
      <id>OBJECT_NAME</id>
      <enabled>Y</enabled>
      <name>OBJECT_NAME</name>
    </field>
    <field>
      <id>OBJECT_COPY</id>
      <enabled>Y</enabled>
      <name>OBJECT_COPY</name>
    </field>
    <field>
      <id>REPOSITORY_DIRECTORY</id>
      <enabled>Y</enabled>
      <name>REPOSITORY_DIRECTORY</name>
    </field>
    <field>
      <id>FILENAME</id>
      <enabled>Y</enabled>
      <name>FILENAME</name>
    </field>
    <field>
      <id>OBJECT_ID</id>
      <enabled>Y</enabled>
      <name>OBJECT_ID</name>
    </field>
    <field>
      <id>OBJECT_REVISION</id>
      <enabled>Y</enabled>
      <name>OBJECT_REVISION</name>
    </field>
    <field>
      <id>PARENT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>PARENT_CHANNEL_ID</name>
    </field>
    <field>
      <id>ROOT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>ROOT_CHANNEL_ID</name>
    </field>
  </channel-log-table>
  <pass_batchid>N</pass_batchid>
  <shared_objects_file/>
  <entries>
    <entry>
      <name>Set AWS Credentials</name>
      <description/>
      <type>SHELL</type>
      <attributes/>
      <filename/>
      <work_directory/>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>#!/bin/bash
export "AWS_ACCESS_KEY_ID=${AWS_S3_ACCESS_KEY}"
#echo "AWS_S3_ACCESS_KEY = ${AWS_S3_ACCESS_KEY}"

export "AWS_SECRET_ACCESS_KEY=${AWS_S3_SECRET_KEY}"
#echo "AWS_S3_BUCKET_NAME=${AWS_S3_BUCKET_NAME}"

export "AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}"

aws configure list</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>112</xloc>
      <yloc>768</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_drilldown (inserted) sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>------------------------------
--
-- Create standard_drug_outcome_drilldown table for use in joins to get all cases for a drug/outcome pair count
--
-- LTS COMPUTING LLC
------------------------------

set search_path = ${DATABASE_SCHEMA};

-- create indexes to speed up this SQL

--drop index if exists standard_case_drug_ix_1;
create index if not exists standard_case_drug_ix_1 on standard_case_drug(primaryid);
--drop index if exists standard_case_drug_ix_2;
create index if not exists standard_case_drug_ix_2 on standard_case_drug(isr);
--drop index if exists standard_case_drug_ix_3;
create index if not exists standard_case_drug_ix_3 on standard_case_drug(standard_concept_id);

--drop index if exists standard_case_adr_ix_1;
create index if not exists standard_case_adr_ix_1 on standard_case_adr(primaryid);
--drop index if exists standard_case_adr_ix_2;
create index if not exists standard_case_adr_ix_2 on standard_case_adr(isr);
--drop index if exists standard_case_adr_ix_3;
create index if not exists standard_case_adr_ix_3 on standard_case_adr(outcome_concept_id);

--drop index if exists standard_drug_outcome_count_ix_1;
create index if not exists standard_drug_outcome_count_ix_1 on standard_drug_outcome_count(drug_concept_id);
--drop index if exists standard_drug_outcome_count_ix_2;
create index if not exists standard_drug_outcome_count_ix_2 on standard_drug_outcome_count(outcome_concept_id);

--drop table if exists standard_drug_outcome_drilldown;
create table if not exists standard_drug_outcome_drilldown as
	select 
		a.drug_concept_id, 
		a.outcome_concept_id, 
		a.snomed_outcome_concept_id, 
		b.primaryid, null as isr, null as caseid
	from standard_drug_outcome_count a
		inner join standard_case_drug b
			on a.drug_concept_id = b.standard_concept_id
		inner join standard_case_adr c
			on a.outcome_concept_id = c.outcome_concept_id
			and b.primaryid = c.primaryid
	union
	select
		a.drug_concept_id,  
		a.outcome_concept_id, 
		a.snomed_outcome_concept_id,  
		null as primary_id, b.isr, null as caseid
	from standard_drug_outcome_count a
		inner join standard_case_drug b
			on a.drug_concept_id = b.standard_concept_id
		inner join standard_case_adr c
			on a.outcome_concept_id = c.outcome_concept_id
			and b.isr = c.isr;

-- populate the caseids that have a primaryid
update standard_drug_outcome_drilldown a
	set caseid = b.caseid
	from unique_all_case b
	where a.primaryid = b.primaryid;

-- populate the caseids that have an isr
update standard_drug_outcome_drilldown a
	set caseid = b.caseid
		from unique_all_case b
	where a.isr = b.isr
		and a.caseid is null;
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>656</xloc>
      <yloc>2240</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>map_meddra_to_snomed (inserted) sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>------------------------------
-- map drug indications and adverse event outcomes (FAERS reactions) and associated drug/outcome pair counts from MedDRA preferred terms to SNOMED-CT concepts
--
-- LTS COMPUTING LLC
------------------------------

set search_path = ${DATABASE_SCHEMA};

-- populate standard_case_indication SNOMED-CT concepts
update standard_case_indication a
		set snomed_indication_concept_id = snomed_concept_id
	from meddra_snomed_mapping b
		where a.indication_concept_id = b.meddra_concept_id;

-- populate standard_case_adr SNOMED-CT concepts
update standard_case_adr a
	set snomed_outcome_concept_id = snomed_concept_id
from meddra_snomed_mapping b
	where a.outcome_concept_id = b.meddra_concept_id;

-- populate standard_drug_outcome_count SNOMED-CT concepts
update standard_drug_outcome_count a
	set snomed_outcome_concept_id = snomed_concept_id
		from meddra_snomed_mapping b
	where a.outcome_concept_id = b.meddra_concept_id;

-- populate standard_drug_outcome_statistics SNOMED-CT concepts
update standard_drug_outcome_statistics a
	set snomed_outcome_concept_id = snomed_concept_id
from meddra_snomed_mapping b
	where a.outcome_concept_id = b.meddra_concept_id;</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>352</xloc>
      <yloc>2224</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_contingency_table_part_1.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>/home/pentaho-secondary/projects-brb265/faers/faersdbstats/stage_5_sqls/derive_standard_drug_outcome_contingency_table_part_1.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>1904</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_count.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>------------------------------
--
-- This SQL script creates drug/outcome combination case counts (counts for pairs of drug RxNorm concept_id, outcome (reaction) Meddra concept_id) 
-- and stores the combination case counts in a new table called standard_drug_outcome_count
--
-- LTS COMPUTING LLC
------------------------------

set search_path = ${DATABASE_SCHEMA};

drop table if exists standard_drug_outcome_count;
create table standard_drug_outcome_count as
select drug_concept_id, outcome_concept_id, count(*) as drug_outcome_pair_count, cast(null as integer) as snomed_outcome_concept_id
from (
	select 'PRIMARYID' || a.primaryid as case_key, a.standard_concept_id as drug_concept_id, b.outcome_concept_id, cast(null as integer) as snomed_outcome_concept_id
			from standard_case_drug a
		inner join standard_case_adr b
			on a.primaryid = b.primaryid and a.isr is null and b.isr is null
		union 
	select 'ISR' || a.isr as case_key, a.standard_concept_id as drug_concept_id, b.outcome_concept_id, cast(null as integer) as snomed_outcome_concept_id
			from standard_case_drug a
		inner join standard_case_adr b
			on a.isr = b.isr and a.isr is not null and b.isr is not null
) aa
group by drug_concept_id, outcome_concept_id;
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>160</xloc>
      <yloc>1600</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_case_adr (inserted) sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>------------------------------
--
-- This SQL script converts the unique legacy LAERS and current FAERS case reactions (adverse event outcomes) MedDRA preferred terms 
-- into MedDRA concept ids in a new table called standard_case_adr 
--
-- LTS COMPUTING LLC
------------------------------

set search_path = ${DATABASE_SCHEMA};

-- create indexes on reac table for improved performance in this SQL
--drop index if exists ix_reac_1;
--drop index if exists ix_reac_2;
create index if not exists ix_reac_1 on reac (upper(pt));
create index if not exists ix_reac_2 on reac (primaryid);
analyze verbose reac;

-- create indexes on reac_legacy table for improved performance in this SQL
--drop index if exists ix_reac_legacy_1;
--drop index if exists ix_reac_legacy_2;
create index if not exists ix_reac_legacy_1 on reac_legacy (upper(pt));
create index if not exists ix_reac_legacy_2 on reac_legacy (isr);
analyze verbose reac_legacy;

--drop table if exists standard_case_adr;
create table if not exists standard_case_adr as
select distinct a.primaryid, a.isr, b.pt, c.concept_id as outcome_concept_id, cast(null as integer) as snomed_outcome_concept_id
	from unique_all_case a
	inner join reac b
		on a.primaryid = b.primaryid
	inner join staging_vocabulary.concept c
		on upper(b.pt) = upper(c.concept_name)
		and c.vocabulary_id = 'MedDRA'
		where a.isr is null
union
select distinct a.primaryid, a.isr, b.pt, c.concept_id as outcome_concept_id, cast(null as integer) as snomed_outcome_concept_id
	from unique_all_case a
inner join reac_legacy b
		on a.isr = b.isr
	inner join staging_vocabulary.concept c
		on upper(b.pt) = upper(c.concept_name)
		and c.vocabulary_id = 'MedDRA'
		where a.isr is not null;
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>576</xloc>
      <yloc>1472</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_case_indication (inserted) sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>------------------------------
--
-- This SQL script converts the indication MedDRA preferred terms into MedDRA concept ids for all unique legacy and current cases
-- in a new table called standard_case_indication 
-- Note. We use a regex to remove leading white space in the indication preferred term field
--
-- LTS COMPUTING LLC
------------------------------

set search_path = ${DATABASE_SCHEMA};

--drop table if exists standard_case_indication; 
create table if not exists standard_case_indication as
select distinct a.primaryid, a.isr, indi_drug_seq, b.indi_pt, c.concept_id as indication_concept_id, cast(null as integer) as snomed_indication_concept_id
	from unique_all_case a
	inner join indi b
		on a.primaryid = b.primaryid
	inner join staging_vocabulary.concept c
		on upper(regexp_replace(b.indi_pt,'^ +','','gi')) = upper(c.concept_name) 
		and c.vocabulary_id = 'MedDRA'
		where a.isr is null
union
select distinct a.primaryid, a.isr, drug_seq, b.indi_pt, c.concept_id as indication_concept_id, cast(null as integer) as snomed_indication_concept_id
	from unique_all_case a
	inner join indi_legacy b
		on a.isr = b.isr
	inner join staging_vocabulary.concept c
		on upper(regexp_replace(b.indi_pt,'^ +','','gi')) = upper(c.concept_name) 
		and c.vocabulary_id = 'MedDRA'
		where a.isr is not null;
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>144</xloc>
      <yloc>1472</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_case_outcome_category.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>${Internal.Entry.Current.Directory}/derive_standard_case_outcome_category.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>976</xloc>
      <yloc>1360</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>standardize_combined_drug_mapping.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>--NOTE THIS STEP THROWS ERRORS IF NOT "SQL from file"</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>${Internal.Entry.Current.Directory}/standardize_combined_drug_mapping.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>144</xloc>
      <yloc>1360</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>create_usagi_import_table.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>-- Create staging table to import USAGI manually mapped drug names
--
-- LTS Computing LLC
-----------------------------------------------------------------------------------------------
set search_path = ${DATABASE_SCHEMA};

--drop table if exists usagi_import;
CREATE TABLE IF NOT EXISTS usagi_import
(
  source_code character varying,
  source_concept_id character varying,
  source_vocabulary_id character varying,
  source_code_description character varying,
  target_concept_id character varying,
  target_vocabulary_id character varying,
  valid_start_date character varying,
  valid_end_date character varying,
  invalid_reason character varying
);</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>656</xloc>
      <yloc>880</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_unique_all_case.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>${FAERSDBSTATS_REPO_LOCATION}/stage_5_sqls/derive_unique_all_case.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>112</xloc>
      <yloc>880</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Wait for 3s</name>
      <description/>
      <type>DELAY</type>
      <attributes/>
      <maximumTimeout>3</maximumTimeout>
      <scaletime>0</scaletime>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>656</xloc>
      <yloc>768</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Set job variables</name>
      <description/>
      <type>SET_VARIABLES</type>
      <attributes/>
      <replacevars>Y</replacevars>
      <filename>${BASE_FILE_DIR}/faers_config.config</filename>
      <file_variable_type>JVM</file_variable_type>
      <fields>
        <field>
          <variable_name>FILE_DIR</variable_name>
          <variable_value>${BASE_FILE_DIR}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>FAERSDBSTATS_REPO_LOCATION</variable_name>
          <variable_value>${FAERSDBSTATS_REPO_LOCATION}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>CEM_DOWNLOAD_DATA_FOLDER</variable_name>
          <variable_value>${CEM_DOWNLOAD_DATA_FOLDER}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>AWS_S3_BUCKET_NAME</variable_name>
          <variable_value>${AWS_S3_BUCKET_NAME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>AWS_S3_ACCESS_KEY</variable_name>
          <variable_value>${AWS_S3_ACCESS_KEY}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>AWS_S3_SECRET_KEY</variable_name>
          <variable_value>${AWS_S3_SECRET_KEY}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_HOST</variable_name>
          <variable_value>${DATABASE_HOST}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_NAME</variable_name>
          <variable_value>${DATABASE_NAME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_SCHEMA</variable_name>
          <variable_value>${DATABASE_SCHEMA}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_USERNAME</variable_name>
          <variable_value>${DATABASE_USERNAME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_PASSWORD</variable_name>
          <variable_value>${DATABASE_PASSWORD}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_LOG_SCHEMA</variable_name>
          <variable_value>${DATABASE_LOG_SCHEMA}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>LOAD_NEW_QUARTER</variable_name>
          <variable_value>${LOAD_NEW_QUARTER}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>LOAD_NEW_YEAR</variable_name>
          <variable_value>${LOAD_NEW_YEAR}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>LOAD_ALL_TIME</variable_name>
          <variable_value>${LOAD_ALL_TIME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>CEM_ORANGE_BOOK_DOWNLOAD_FILENAME</variable_name>
          <variable_value>${CEM_ORANGE_BOOK_DOWNLOAD_FILENAME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>BASE_FILE_DIR</variable_name>
          <variable_value>${BASE_FILE_DIR}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
      </fields>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>352</xloc>
      <yloc>656</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Start</name>
      <description/>
      <type>SPECIAL</type>
      <attributes/>
      <start>Y</start>
      <dummy>N</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>112</xloc>
      <yloc>656</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_statistics.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>------------------------------
--
-- This SQL script creates a statistics table called standard_drug_outcome_stats (using the counts from the previously calculated 2x2 contingency table)
-- with the following statistics for each drug/outcome pair:
--
-- 1) Case count
-- 2) Proportional Reporting Ratio (PRR) along with the 95% CI upper and lower values
-- 3) Reporting Odds Ratio (ROR) along with the 95% CI upper and lower values
--
-- PRR for pair:(drug P, outcome R) is calculated as (A / (A + B)) / (C / (C + D)
--
-- ROR for pair:(drug P, outcome R) is calculated as (A / C) / (B / D)
--
-- Where:
--		A = case_count for the pair:(drug P, outcome R)
--		B = sum(case_count) for all pairs:(drug P, all outcomes except outcome R)
--		C = sum(case_count) for all pairs:(all drugs except drug P, outcome R)
--		D = sum(case_count) for all pairs:(all drugs except drug P, all outcomes except outcome R)
--
-- Note if C is 0 then the resulting PRR and ROR values will be null. Potentially a relatively high constant value
-- could be assigned instead, to indicate a potential PRR and ROR signal in these cases.
--
--
-- Standard deviations are obtained from Douglas G Altman's Practical Statistics for Medical Research. 1999. Chapter 10.11. Page 267 
--
-- LTS COMPUTING LLC
------------------------------

set search_path = ${DATABASE_SCHEMA};

--drop table if exists standard_drug_outcome_statistics;
create table if not exists standard_drug_outcome_statistics as
select drug_concept_id, outcome_concept_id, cast(null as integer) as snomed_outcome_concept_id, 
    count_a as case_count,
    round((count_a / (count_a + count_b)) / (count_c / (count_c + count_d)),5) as prr,
    round(exp(ln((count_a / (count_a + count_b)) / (count_c / (count_c + count_d)))+1.96*sqrt((1.0/count_a)-(1.0/(count_a+count_b))+(1.0/count_c)-(1.0/(count_c+count_d)))),5) as prr_95_percent_upper_confidence_limit,
    round(exp(ln((count_a / (count_a + count_b)) / (count_c / (count_c + count_d)))-1.96*sqrt((1.0/count_a)-(1.0/(count_a+count_b))+(1.0/count_c)-(1.0/(count_c+count_d)))),5) as prr_95_percent_lower_confidence_limit,
    round(((count_a / count_c) / (count_b / count_d)),5) as ror,
    round(exp((ln((count_a / count_c) / (count_b / count_d)))+1.96*sqrt((1.0/count_a)+(1.0/count_b)+(1.0/count_c)+(1.0/count_d))),5) as ror_95_percent_upper_confidence_limit,
    round(exp((ln((count_a / count_c) / (count_b / count_d)))-1.96*sqrt((1.0/count_a)+(1.0/count_b)+(1.0/count_c)+(1.0/count_d))),5) as ror_95_percent_lower_confidence_limit
from standard_drug_outcome_contingency_table;
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>160</xloc>
      <yloc>2208</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Log STAGE 5 COMPLETE</name>
      <description/>
      <type>SHELL</type>
      <attributes/>
      <filename/>
      <work_directory/>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>#!/bin/bash
log_location=${BASE_FILE_DIR}/logs/${LOG_FILENAME}
printf '\n' >> $log_location
echo "#######################################################" >> $log_location
echo "################ STAGE 5 COMPLETE #####################" >> $log_location
echo "#######################################################" >> $log_location
printf '\n\n' >> $log_location
echo ' You might have a database administrator vacuum db and reindex ' >> $log_location</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>96</xloc>
      <yloc>2320</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_contingency_table_part_5.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>F</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>/home/pentaho-secondary/projects-brb265/faers/faersdbstats/stage_5_sqls/derive_standard_drug_outcome_contingency_table_part_5.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>2160</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_contingency_table_part_2.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>/home/pentaho-secondary/projects-brb265/faers/faersdbstats/stage_5_sqls/derive_standard_drug_outcome_contingency_table_part_2.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>1968</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_contingency_table_part_3.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>/home/pentaho-secondary/projects-brb265/faers/faersdbstats/stage_5_sqls/derive_standard_drug_outcome_contingency_table_part_3.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>2032</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_contingency_table_part_4.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>/home/pentaho-secondary/projects-brb265/faers/faersdbstats/stage_5_sqls/derive_standard_drug_outcome_contingency_table_part_4.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>2096</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Wait for 3s (2)</name>
      <description/>
      <type>DELAY</type>
      <attributes/>
      <maximumTimeout>3</maximumTimeout>
      <scaletime>0</scaletime>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>976</xloc>
      <yloc>1472</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Wait for 3s (3)</name>
      <description/>
      <type>DELAY</type>
      <attributes/>
      <maximumTimeout>3</maximumTimeout>
      <scaletime>0</scaletime>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>528</xloc>
      <yloc>1600</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Wait for 3s (4)</name>
      <description/>
      <type>DELAY</type>
      <attributes/>
      <maximumTimeout>3</maximumTimeout>
      <scaletime>0</scaletime>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>672</xloc>
      <yloc>1936</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>create standard_drug_outcome_contingency_table from cem_ddl.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>-- faers.standard_drug_outcome_contingency_table definition

-- Drop table

-- DROP TABLE faers.standard_drug_outcome_contingency_table;

set search_path = ${DATABASE_SCHEMA};

CREATE TABLE if not exists faers.standard_drug_outcome_contingency_table (
	drug_concept_id int4 NULL,
	outcome_concept_id int4 NULL,
	count_a int8 NULL,
	count_b numeric NULL,
	count_c numeric NULL,
	count_d numeric NULL
);
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>592</xloc>
      <yloc>1664</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>derive_standard_drug_outcome_contingency_table.sql (all)</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>/home/pentaho-secondary/projects-brb265/faers/faersdbstats/stage_5_sqls/derive_standard_drug_outcome_contingency_table.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>1760</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Log "STAGE 5 TOOK DERIVE_* step SHORT ROUTE"</name>
      <description/>
      <type>SHELL</type>
      <attributes/>
      <filename/>
      <work_directory/>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>#!/bin/bash
log_location=${BASE_FILE_DIR}/logs/${LOG_FILENAME}
printf '\n' >> $log_location
echo "################ STAGE 5 TOOK DERIVE_* step SHORT ROUTE #####################" >> $log_location
printf '\n' >> $log_location</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>160</xloc>
      <yloc>1856</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Log "STAGE 5 TOOK DERIVE FAILED SO DERIVE_* step LONG ROUTE"</name>
      <description/>
      <type>SHELL</type>
      <attributes/>
      <filename/>
      <work_directory/>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>#!/bin/bash
log_location=${BASE_FILE_DIR}/logs/${LOG_FILENAME}
printf '\n' >> $log_location
echo "################ STAGE 5 TOOK DERIVE FAILED SO DERIVE_* step LONG ROUTE #####################" >> $log_location
printf '\n' >> $log_location</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>1840</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>Log "STAGE 5 STARTED"</name>
      <description/>
      <type>SHELL</type>
      <attributes/>
      <filename/>
      <work_directory/>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>#!/bin/bash
log_location=${BASE_FILE_DIR}/logs/${LOG_FILENAME}
printf '\n' >> $log_location
echo "################ Stage_5_SQLs has started #####################" >> $log_location
printf '\n' >> $log_location</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>656</xloc>
      <yloc>656</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>natural product vocabulary workflow step 3</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>-- from https://github.com/rkboyce/NaPDI-pv/tree/master/np-terminology-imports

--- APPROACH FOR NON-AWS --- RUN AS SUPER USER ON THE DATABASE OF INTEREST
alter table staging_vocabulary.concept disable trigger all;
alter table staging_vocabulary.vocabulary disable trigger all;
alter table staging_vocabulary.domain  disable trigger all;
alter table staging_vocabulary.concept_class disable trigger all;
alter table staging_vocabulary.relationship disable trigger all;
alter table staging_vocabulary.concept_relationship disable trigger all;

DELETE FROM staging_vocabulary.concept cascade WHERE concept_id BETWEEN -9999999 AND -7000000 ;
DELETE FROM staging_vocabulary.vocabulary cascade WHERE vocabulary_concept_id BETWEEN -9999999 AND -7000000 ;
DELETE FROM staging_vocabulary.domain cascade WHERE domain_concept_id BETWEEN -9999999 AND -7000000 ;
DELETE FROM staging_vocabulary.concept_class cascade WHERE concept_class_concept_id BETWEEN -9999999 AND -7000000 ;
DELETE FROM staging_vocabulary.relationship cascade WHERE relationship_concept_id BETWEEN -9999999 AND -7000000 ;
DELETE FROM staging_vocabulary.concept_relationship cascade WHERE relationship_id like 'napdi_%';

alter table staging_vocabulary.concept enable trigger all;
alter table staging_vocabulary.vocabulary enable trigger all;
alter table staging_vocabulary.domain  enable trigger all;
alter table staging_vocabulary.concept_class enable trigger all;
alter table staging_vocabulary.relationship enable trigger all;
alter table staging_vocabulary.concept_relationship enable trigger all;</sql>
      <useVariableSubstitution>F</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>736</xloc>
      <yloc>1056</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>natural product vocabulary workflow step 1</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>-- update GSRS NPs, common names, and constituents in lb_to_common_names_tsv, test_srs_np, and test_srs_np_constituent (currently in the scratch_sanya schema of the GSRS database). See GSRS database query notes

</sql>
      <useVariableSubstitution>F</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>400</xloc>
      <yloc>1072</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>natural product vocabulary workflow step 2</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>-- update the manually curated NP spelling variations in np_faers_reference_set (currently in the scratch_sanya schema of the CEM database)</sql>
      <useVariableSubstitution>F</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>584</xloc>
      <yloc>1093</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>natural product vocabulary workflow step 4</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>-- run the SQL NP terminology additions script
-- https://github.com/rkboyce/NaPDI-pv/blob/master/np-terminology-imports/napdi_np_vocab_workflow_DEC_2022_Israel_mappings.sql
</sql>
      <useVariableSubstitution>F</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>368</xloc>
      <yloc>1200</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>natural product vocabulary workflow step 5</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>-- test that the vocabulary is working and makes sense using queries like the following:</sql>
      <useVariableSubstitution>F</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>224</xloc>
      <yloc>1264</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>faers-deduplication-strategy-DECEMBER-2022-USES-VIGIBASE.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql/>
      <useVariableSubstitution>F</useVariableSubstitution>
      <sqlfromfile>T</sqlfromfile>
      <sqlfilename>${BASE_FILE_DIR}/faersdbstats/stage_5_sqls/faers-deduplication-strategy-DECEMBER-2022-USES-VIGIBASE.sql</sqlfilename>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>1264</xloc>
      <yloc>1488</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>map_all_drugname_to_rxnorm.sql</name>
      <description/>
      <type>SHELL</type>
      <attributes/>
      <filename>$(Internal.Entry.Current.Directory)/map_all_drugname_to_rxnorm.sql</filename>
      <work_directory>${Internal.Entry.Current.Directory}</work_directory>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>#!/bin/bash

set -e

# Load environment variables from the config file
source ../../faers_config.config

# Run SQL with envsubst to substitute ${â€¦} in the SQL
envsubst &lt; ./map_all_drugname_to_rxnorm.sql | \
  PGPASSWORD="${DATABASE_PASSWORD}" \
  psql -v ON_ERROR_STOP=1 \
       -h "$DATABASE_HOST" \
       -p "$DATABASE_PORT" \
       -U "$DATABASE_USERNAME" \
       -d "$DATABASE_NAME"
</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>112</xloc>
      <yloc>1008</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>generate_drug_export_for_usagi.sql</name>
      <description/>
      <type>SQL</type>
      <attributes/>
      <sql>-- This SQL generates the set of unmatched drug names with a dummy source_id and a source frequency based on frequency of cases
-- In postgres SQL client save the results to a csv file and then import that csv file to usagi for manual code curation
--
-- LTS Computing LLC
--------------------------------------------
set search_path = ${DATABASE_SCHEMA};

select row_number() over () as source_code, 
	upper(drug_name_original) as source_code_description, 
	count(*) as frequency -- (case frequency)
from combined_drug_mapping where concept_id is null
	group by upper(drug_name_original)
	order by count(*) desc
</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename/>
      <sendOneStatement>F</sendOneStatement>
      <connection>${DATABASE_NAME}</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>384</xloc>
      <yloc>976</yloc>
      <attributes_kjc/>
    </entry>
  </entries>
  <hops>
    <hop>
      <from>derive_standard_case_indication (inserted) sql</from>
      <to>derive_standard_case_adr (inserted) sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_case_outcome_category.sql</from>
      <to>derive_standard_case_indication (inserted) sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>standardize_combined_drug_mapping.sql</from>
      <to>derive_standard_case_outcome_category.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>map_meddra_to_snomed (inserted) sql</from>
      <to>derive_standard_drug_outcome_drilldown (inserted) sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_unique_all_case.sql</from>
      <to>create_usagi_import_table.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Start</from>
      <to>Set job variables</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Set AWS Credentials</from>
      <to>Wait for 3s</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_drilldown (inserted) sql</from>
      <to>Log STAGE 5 COMPLETE</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_statistics.sql</from>
      <to>map_meddra_to_snomed (inserted) sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_contingency_table_part_5.sql</from>
      <to>derive_standard_drug_outcome_statistics.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_contingency_table_part_2.sql</from>
      <to>derive_standard_drug_outcome_contingency_table_part_3.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_contingency_table_part_3.sql</from>
      <to>derive_standard_drug_outcome_contingency_table_part_4.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_contingency_table_part_4.sql</from>
      <to>derive_standard_drug_outcome_contingency_table_part_5.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_case_adr (inserted) sql</from>
      <to>Wait for 3s (2)</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>N</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_count.sql</from>
      <to>Wait for 3s (3)</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_contingency_table_part_1.sql</from>
      <to>Wait for 3s (4)</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>N</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Wait for 3s (4)</from>
      <to>derive_standard_drug_outcome_contingency_table_part_2.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>create standard_drug_outcome_contingency_table from cem_ddl.sql</from>
      <to>derive_standard_drug_outcome_contingency_table.sql (all)</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_contingency_table.sql (all)</from>
      <to>Log "STAGE 5 TOOK DERIVE_* step SHORT ROUTE"</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Log "STAGE 5 TOOK DERIVE_* step SHORT ROUTE"</from>
      <to>derive_standard_drug_outcome_statistics.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>derive_standard_drug_outcome_contingency_table.sql (all)</from>
      <to>Log "STAGE 5 TOOK DERIVE FAILED SO DERIVE_* step LONG ROUTE"</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Log "STAGE 5 TOOK DERIVE FAILED SO DERIVE_* step LONG ROUTE"</from>
      <to>derive_standard_drug_outcome_contingency_table_part_1.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Set job variables</from>
      <to>Log "STAGE 5 STARTED"</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Log "STAGE 5 STARTED"</from>
      <to>Set AWS Credentials</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Wait for 3s</from>
      <to>derive_unique_all_case.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>natural product vocabulary workflow step 3</from>
      <to>standardize_combined_drug_mapping.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Wait for 3s (2)</from>
      <to>faers-deduplication-strategy-DECEMBER-2022-USES-VIGIBASE.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>faers-deduplication-strategy-DECEMBER-2022-USES-VIGIBASE.sql</from>
      <to>derive_standard_drug_outcome_count.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>create_usagi_import_table.sql</from>
      <to>map_all_drugname_to_rxnorm.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>map_all_drugname_to_rxnorm.sql</from>
      <to>generate_drug_export_for_usagi.sql</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
  </hops>
  <notepads>
    <notepad>
      <note>Stage 5 - Drug Mapping

Prereq's
  having run...
    stage_1 then...
    stage_2 then...
    stage_3_domain_transform
  and
    stage_3_domain_transform (if data from 2012 Q3 or older)
    stage_4_meta

ABOUT THIS STAGE
-derive_unique_all_case.sql			-makes LAERS data like FAERS data and removes duplicates created in process
-map_all_drugname_to_rxnorm
-standardize_combined_drug_mapping
-derive_standard_case_outcome_category
-derive_standard_case_indication.sql
-derive_standard_case_adr.sql
-derive_standard_drug_outcome_count.sql
-derive_standard_drug_outcome_contingency_table.sql    -create index if not exists
-derive_standard_drug_outcome_statistics.sql
-map_meddra_to_snomed.sql
-derive_standard_drug_outcome_drilldown.sql       -create table if not exists   -create index if not exists

Troubleshooting:
if "Logging" tab stops producing output restart spoon
if Java Null Pointer Error (and/or job 'job") restart spoon then rebuild failing step as if new


</note>
      <xloc>0</xloc>
      <yloc>0</yloc>
      <width>848</width>
      <heigth>550</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>^creates standard_drug_outcome_count table
implement de-duplication procress after this?
</note>
      <xloc>16</xloc>
      <yloc>1664</yloc>
      <width>336</width>
      <heigth>64</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>^combined_drug_mapping
drug_nda_mapping</note>
      <xloc>16</xloc>
      <yloc>1072</yloc>
      <width>198</width>
      <heigth>46</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>our natural product vocabulary goes here





are we going to pentaho 
workflow this "workflow" 
https://github.com/rkboyce/NaPDI-pv/tree/master/np-terminology-imports#workflow? </note>
      <xloc>304</xloc>
      <yloc>1040</yloc>
      <width>623</width>
      <heigth>172</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>bring in our new de-duplication method (references vigibase but we didn't update that...)

...for new quarter


TODO put
https://github.com/rkboyce/NaPDI-pv/blob/master/deduplication-strategy/review-of-deduplication-analysis-from-dec-2022.sql
into stage 6
</note>
      <xloc>1056</xloc>
      <yloc>1456</yloc>
      <width>899</width>
      <heigth>172</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>these are drug-adverse-disproportionate calculations                            




























</note>
      <xloc>16</xloc>
      <yloc>1760</yloc>
      <width>496</width>
      <heigth>550</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>need to calculcate drug drug adverse event calculation

where's this code?
the 2 not validation sql's from:
https://github.com/rkboyce/NaPDI-pv/tree/master/DDI_signals

https://github.com/rkboyce/NaPDI-pv/issues/22</note>
      <xloc>880</xloc>
      <yloc>1648</yloc>
      <width>452</width>
      <heigth>136</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <attributes>
    <group>
      <name>METASTORE.pentaho</name>
      <attribute>
        <key>Default Run Configuration</key>
        <value>{"namespace":"pentaho","id":"Default Run Configuration","name":"Default Run Configuration","description":"Defines a default run configuration","metaStoreName":null}</value>
      </attribute>
    </group>
    <group>
      <name>{"_":"Embedded MetaStore Elements","namespace":"pentaho","type":"Default Run Configuration"}</name>
    </group>
  </attributes>
</job>
