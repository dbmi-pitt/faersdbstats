<?xml version="1.0" encoding="UTF-8"?>
<job>
  <name>faers_stage_1_setup</name>
  <description/>
  <extended_description/>
  <job_version/>
  <directory>/</directory>
  <created_user>-</created_user>
  <created_date>2022/06/09 09:52:05.111</created_date>
  <modified_user>-</modified_user>
  <modified_date>2022/06/09 09:52:05.111</modified_date>
  <parameters>
    </parameters>
  <slaveservers>
    </slaveservers>
  <job-log-table>
    <connection/>
    <schema/>
    <table/>
    <size_limit_lines/>
    <interval/>
    <timeout_days/>
    <field>
      <id>ID_JOB</id>
      <enabled>Y</enabled>
      <name>ID_JOB</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>JOBNAME</name>
    </field>
    <field>
      <id>STATUS</id>
      <enabled>Y</enabled>
      <name>STATUS</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>STARTDATE</id>
      <enabled>Y</enabled>
      <name>STARTDATE</name>
    </field>
    <field>
      <id>ENDDATE</id>
      <enabled>Y</enabled>
      <name>ENDDATE</name>
    </field>
    <field>
      <id>LOGDATE</id>
      <enabled>Y</enabled>
      <name>LOGDATE</name>
    </field>
    <field>
      <id>DEPDATE</id>
      <enabled>Y</enabled>
      <name>DEPDATE</name>
    </field>
    <field>
      <id>REPLAYDATE</id>
      <enabled>Y</enabled>
      <name>REPLAYDATE</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>Y</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>EXECUTING_SERVER</id>
      <enabled>N</enabled>
      <name>EXECUTING_SERVER</name>
    </field>
    <field>
      <id>EXECUTING_USER</id>
      <enabled>N</enabled>
      <name>EXECUTING_USER</name>
    </field>
    <field>
      <id>START_JOB_ENTRY</id>
      <enabled>N</enabled>
      <name>START_JOB_ENTRY</name>
    </field>
    <field>
      <id>CLIENT</id>
      <enabled>N</enabled>
      <name>CLIENT</name>
    </field>
  </job-log-table>
  <jobentry-log-table>
    <connection/>
    <schema/>
    <table/>
    <timeout_days/>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>TRANSNAME</name>
    </field>
    <field>
      <id>JOBENTRYNAME</id>
      <enabled>Y</enabled>
      <name>STEPNAME</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>RESULT</id>
      <enabled>Y</enabled>
      <name>RESULT</name>
    </field>
    <field>
      <id>NR_RESULT_ROWS</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_ROWS</name>
    </field>
    <field>
      <id>NR_RESULT_FILES</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_FILES</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>N</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>COPY_NR</id>
      <enabled>N</enabled>
      <name>COPY_NR</name>
    </field>
  </jobentry-log-table>
  <channel-log-table>
    <connection/>
    <schema/>
    <table/>
    <timeout_days/>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>LOGGING_OBJECT_TYPE</id>
      <enabled>Y</enabled>
      <name>LOGGING_OBJECT_TYPE</name>
    </field>
    <field>
      <id>OBJECT_NAME</id>
      <enabled>Y</enabled>
      <name>OBJECT_NAME</name>
    </field>
    <field>
      <id>OBJECT_COPY</id>
      <enabled>Y</enabled>
      <name>OBJECT_COPY</name>
    </field>
    <field>
      <id>REPOSITORY_DIRECTORY</id>
      <enabled>Y</enabled>
      <name>REPOSITORY_DIRECTORY</name>
    </field>
    <field>
      <id>FILENAME</id>
      <enabled>Y</enabled>
      <name>FILENAME</name>
    </field>
    <field>
      <id>OBJECT_ID</id>
      <enabled>Y</enabled>
      <name>OBJECT_ID</name>
    </field>
    <field>
      <id>OBJECT_REVISION</id>
      <enabled>Y</enabled>
      <name>OBJECT_REVISION</name>
    </field>
    <field>
      <id>PARENT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>PARENT_CHANNEL_ID</name>
    </field>
    <field>
      <id>ROOT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>ROOT_CHANNEL_ID</name>
    </field>
  </channel-log-table>
  <pass_batchid>N</pass_batchid>
  <shared_objects_file/>
  <entries>
    <entry>
      <name>Start</name>
      <description/>
      <type>SPECIAL</type>
      <attributes/>
      <start>Y</start>
      <dummy>N</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>48</xloc>
      <yloc>64</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>set variables</name>
      <description/>
      <type>SET_VARIABLES</type>
      <attributes/>
      <replacevars>Y</replacevars>
      <filename/>
      <file_variable_type>JVM</file_variable_type>
      <fields>
        <field>
          <variable_name>BASE_FILE_DIR</variable_name>
          <variable_value>${BASE_FILE_DIR}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>FAERSDBSTATS_REPO_LOCATION</variable_name>
          <variable_value>${FAERSDBSTATS_REPO_LOCATION}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>CEM_DOWNLOAD_DATA_FOLDER</variable_name>
          <variable_value>${CEM_DOWNLOAD_DATA_FOLDER}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>AWS_S3_BUCKET_NAME</variable_name>
          <variable_value>${AWS_S3_BUCKET_NAME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>AWS_S3_ACCESS_KEY</variable_name>
          <variable_value>${AWS_S3_ACCESS_KEY}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>AWS_S3_SECRET_KEY</variable_name>
          <variable_value>${AWS_S3_SECRET_KEY}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_HOST</variable_name>
          <variable_value>${DATABASE_HOST}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_NAME</variable_name>
          <variable_value>${DATABASE_NAME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_SCHEMA</variable_name>
          <variable_value>${DATABASE_SCHEMA}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_USERNAME</variable_name>
          <variable_value>${DATABASE_NAME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_PASSWORD</variable_name>
          <variable_value>${DATABASE_PASSWORD}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>DATABASE_LOG_SCHEMA</variable_name>
          <variable_value>${DATABASE_LOG_SCHEMA}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>LOAD_NEW_DATA</variable_name>
          <variable_value>${LOAD_NEW_DATA}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>LOAD_NEW_QUARTER</variable_name>
          <variable_value>${LOAD_NEW_QUARTER}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>LOAD_NEW_YEAR</variable_name>
          <variable_value>${LOAD_NEW_YEAR}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>LOAD_ALL_TIME</variable_name>
          <variable_value>${LOAD_ALL_TIME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
        <field>
          <variable_name>CEM_ORANGE_BOOK_DOWNLOAD_FILENAME</variable_name>
          <variable_value>${CEM_ORANGE_BOOK_DOWNLOAD_FILENAME}</variable_value>
          <variable_type>JVM</variable_type>
        </field>
      </fields>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>176</xloc>
      <yloc>64</yloc>
      <attributes_kjc/>
    </entry>
    <entry>
      <name>set aws credentials</name>
      <description/>
      <type>SHELL</type>
      <attributes/>
      <filename/>
      <work_directory/>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile/>
      <set_append_logfile>N</set_append_logfile>
      <logext/>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>N</insertScript>
      <script/>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>304</xloc>
      <yloc>64</yloc>
      <attributes_kjc/>
    </entry>
  </entries>
  <hops>
    <hop>
      <from>Start</from>
      <to>set variables</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
  </hops>
  <notepads>
    <notepad>
      <note>FAERS SET-UP

Preq's
- AWS S3
- Postgres
- a database connection established within Pentaho (edit > show used environment variables... define host, db, user, pw)
- a properly configured faers.config file
- omop data loaded into vocabulary schema (or proper license to obtain the data)
-data's in staging_vocabulary for create_meddra_snomed_mapping.sql

ABOUT EACH STEP
-set job variables						-brings in environment variables
-Create pdi_logging table			-creates the pentaho logging database tables
-update LOG SQL						-updates pdi_logging for pentaho 9
SUCCESS IF LOAD_ALL_TIME=1		**USE CASE LOGIC***
-orange_book_job					-downloads s3 data and uploads it to s3 then inputs it into the databse w/ orange_book_transform
-nda													-create table and index if not exists
-country_codes_job					-creates country codes table, uploads to s3, and inputs data w/ country_code_transform</note>
      <xloc>458</xloc>
      <yloc>115</yloc>
      <width>906</width>
      <heigth>316</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <attributes/>
</job>
